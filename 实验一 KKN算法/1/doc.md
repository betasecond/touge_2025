任务描述
相关知识
什么是K最近邻算法
kNN算法的优缺点
闯关要求
任务描述
本关任务：通过学习本关知识，完成选择题。

相关知识
为了完成本关任务，你需要掌握：

什么是kNN算法；

kNN算法的优缺点。

什么是K最近邻算法
在许多机器学习相关的书籍当中，最开始被介绍的算法很多都是kNN算法。这是因为kNN算法与机器学习中的其他算法相比有着简单易懂的特点。

机器学习让人真正感到困难的部分其实是它的数学部分，很多数学基础不好的同学在学习机器学习时看见满篇的多元求导恐怕都快疯了吧。这确实是一个无可避免的门槛，虽然很多书都会说不用看数学也可以学会机器学习，但这样学来的知识宛若无根之木，是靠不住的，大家在学习知识的时候一定不能只注重怎么实现，也要注意其背后的原理，知其然而知其所以然才是我们的目标。

但kNN算法则没有这方面的问题，它的原理十分简单，在介绍它的理论时，我们不需要复杂的推导就可以向大家清楚地说明它的由来，确确实实是一个很适合入门的算法。

kNN算法属于监督学习，监督学习所需要做的是在给定一部分带有特征和标签两部分数据的情况下，根据这一部分的特征和数据建立一个模型，之后当我们输入新的特征时，这个模型可以返回这种特征所应该贴上的标签。

这段话有点绕，但大家如果不理解的话需要多读几遍。

好，现在我们该怎么样从原有的数据中建立一个模型呢？kNN算法的思想就是，物以类聚人以群分。即相似的人和物会相聚在一起。



如果觉得有点抽象的话，就看一下上面这个图，是不是就一点感觉了呢？

然后我们现在就来描述一下kNN算法吧：

计算待测数据与已有的数据之间的距离；

按照距离的递增关系排序；

选取距离最小的K个点；

取这K个点中的最多的类别作为待测数据的类别。

算法步骤虽然有4步，但用一句话就能说明白。kNN算法判定待测数据属于哪个类别的依据就是根据离它最近的k个点的类别。哪个类别多，它就属于哪个类别。很深刻的体现了“近朱者赤，近墨者黑”的思想。



如图所示，当我们设定K为3时，离绿色的待测点最近的3个点的类别分别为蓝色，红色，红色。由于蓝红的比分是1:2，所以绿色的待测点属于红色类。

当设定K为5时，离绿色的待测点最近的5个点的类别分别为红色、红色、蓝色、蓝色、蓝色。蓝红的比分是3:2，所以绿色的待测点属于蓝色类。

kNN算法的优缺点
任何事物都有优缺点，kNN算法也不例外。kNN算法的优点有：

理解简单，数学知识基本为0；

既能用于分来，又能用于回归；

支持多分类。

kNN算法可以用于回归，回归的思路是将离待测点最近的k个点的平均值作为待测点的回归预测结果。

kNN算法在测试阶段是看离待测点最近的k个点的类别比分，所以不管训练数据中有多少种类别，都可以通过类别比分来确定待测点类别。

注意：当然会有类别比分打平的情况，这种情况下可以看待测点离哪个类别最近，选最近的类别作为待测点的预测类别。

当然kNN算法的缺点也很明显，就是当训练集数据量比较大时，预测过程的效率很低。这是因为kNN算法在预测过程中需要计算待测点与训练集中所有点的距离并排序。可想而知，当数据量比较大的时候，效率会奇低。对于时间敏感的业务不太适合。

闯关要求
根据所学知识完成右侧选择题。

开始你的任务吧，祝你成功！